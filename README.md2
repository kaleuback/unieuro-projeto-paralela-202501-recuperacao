1) Seguran√ßa da API (fa√ßa IMEDIATAMENTE)

Se voc√™ ainda usa a chave que vazou, revogue-a agora no painel da OpenAI (Platform ‚Üí API Keys).

Gere uma nova chave e s√≥ use localmente / em secrets do HuggingFace.

NUNCA coloque a chave em c√≥digo versionado. Sempre use .env local e Settings ‚Üí Secrets no HuggingFace.

Arquivo local .env (n√£o versionar):

OPENAI_API_KEY=sk-...


E adicione no .gitignore:

.env





2) Preparar ambiente (VS Code)

Instala:

Python 3.10+

VS Code + extens√£o Python (Pylance opcional)

Git (linha de comando)

No terminal do VS Code:

python --version
python -m venv .venv
# Ative o venv
# Windows:
.venv\Scripts\activate
# macOS / Linux:
source .venv/bin/activate

pip install --upgrade pip
pip install openai streamlit python-dotenv pandas scikit-learn


Crie estrutura de pastas:

meu_classificador_filmes/
  src/
    classificador_sentimento.py
    streamlit_app.py
  data/
    imdb_small.csv
  .env.example
  requirements.txt
  README.md
  .gitignore


.gitignore exemplo:

.env
.venv/
__pycache__/
*.pyc


requirements.txt m√≠nimo:

openai>=1.0.0
streamlit
python-dotenv
pandas
scikit-learn


.env.example (commitar este, n√£o o .env):

OPENAI_API_KEY=COLOQUE_AQUI_SUA_CHAVE













3) Baixar a base (IMDB) e criar amostra

Baixe do Kaggle: imdb-dataset-of-50k-movie-reviews (CSV).

Coloque em data/imdb.csv.

Para acelerar testes locais, gere uma amostra pequena (ex: 100 reviews):

script scripts/create_sample.py (opcional):

import pandas as pd
df = pd.read_csv("data/imdb.csv")
df_sample = df.sample(n=200, random_state=42)
df_sample.to_csv("data/imdb_small.csv", index=False)
print("sample created")












4) Implementa√ß√£o ‚Äî scripts essenciais
A ‚Äî Script de teste r√°pido (src/classificador_sentimento.py)

Objetivo: testar chamadas √† OpenAI + prompt, receber JSON e parsear.

# src/classificador_sentimento.py
import os
import json
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def classificar_review(texto):
    prompt = f"""
Voc√™ √© um classificador de reviews de filmes.
Classifique o sentimento como Positivo, Negativo ou Neutro.
Review: "{texto}"
Responda estritamente em JSON:
{{ "classificacao": "", "justificativa": "" }}
"""
    resp = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=200
    )
    content = resp.choices[0].message["content"].strip()
    try:
        # tentativa de parse seguro
        j = json.loads(content)
    except Exception:
        # fallback: tentar extrair manualmente
        j = {"classificacao": content, "justificativa": ""}
    return j

if __name__ == "__main__":
    teste = "O filme foi incr√≠vel, atua√ß√µes sensacionais e roteiro envolvente."
    print(classificar_review(teste))


Importante: use max_tokens controlado; monitore custo. Trate exce√ß√µes de rate limit e API errors.

B ‚Äî Streamlit (src/streamlit_app.py)
# src/streamlit_app.py
import streamlit as st
import os, json
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

st.set_page_config(page_title="Classificador de Reviews de Filmes", layout="centered")
st.title("üé¨ Classificador de Reviews de Filmes (gpt-4.1-nano)")

texto = st.text_area("Digite a review do usu√°rio:", height=200)
if st.button("Classificar"):
    if not texto.strip():
        st.warning("Escreva um texto antes de classificar.")
    else:
        with st.spinner("Consultando a LLM..."):
            prompt = f"""
Voc√™ √© um classificador de reviews de filmes.
Classifique o sentimento como Positivo, Negativo ou Neutro.
Review: "{texto}"
Responda estritamente em JSON:
{{ "classificacao": "", "justificativa": "" }}
"""
            try:
                resp = client.chat.completions.create(
                    model="gpt-4.1-nano",
                    messages=[{"role":"user","content":prompt}],
                    max_tokens=200
                )
                content = resp.choices[0].message["content"].strip()
                try:
                    j = json.loads(content)
                except:
                    j = {"classificacao": content, "justificativa": ""}
                st.subheader("Resultado")
                st.markdown(f"**Classifica√ß√£o:** {j.get('classificacao')}")
                st.write("**Justificativa:**")
                st.write(j.get("justificativa"))
                st.json(j)
            except Exception as e:
                st.error(f"Erro na API: {e}")












5) Rodando localmente e testes

Ative venv e rode:

# testar script
python src/classificador_sentimento.py

# rodar Streamlit
streamlit run src/streamlit_app.py


Teste com 10 frases variadas (positivo/negativo/neutro). Verifique se a resposta JSON √© v√°lida.












6) Avalia√ß√£o com dataset (batch) e m√©tricas

Crie src/eval_batch.py para classificar v√°rias reviews e calcular m√©tricas (usando dados rotulados do IMDB):

# src/eval_batch.py
import pandas as pd
from classificador_sentimento import classificar_review
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

df = pd.read_csv("data/imdb_small.csv")  # colunas: review, sentiment (positive/negative)
y_true = []
y_pred = []

for _, row in df.iterrows():
    text = row['review']
    gt = row.get('sentiment')  # 'positive'/'negative'
    res = classificar_review(text)
    pred = res.get('classificacao', '').lower()
    # mapear para positive/negative/neutro conforme necess√°rio
    if 'pos' in pred:
        p = 'positive'
    elif 'neg' in pred:
        p = 'negative'
    else:
        p = 'neutral'
    y_true.append(gt)
    y_pred.append(p)

print("Accuracy:", accuracy_score(y_true, y_pred))
print(classification_report(y_true, y_pred))
print(confusion_matrix(y_true, y_pred))


Nota: classificar em batch com a API √© caro ‚Äî fa√ßa amostras pequenas (ex.: 50-200) quando estiver testando. Para avalia√ß√£o em larga escala, prefira um modelo local (n√£o exigido aqui) ou crie prompts mais curtos.









7) Controle de custo e boas pr√°ticas

Use amostras pequenas antes de escalar.

max_tokens conservador (ex.: 150‚Äì250).

Reaproveite respostas quando poss√≠vel (cache).

Use retries exponenciais para erros de rede.

Logs: registre lat√™ncia e custo por requisi√ß√£o.










8) Versionamento no GitHub (via VS Code)

No terminal / VS Code:

git init
git add .
git commit -m "First commit - classificador de filmes"
git branch -M main
# criar repo no GitHub via site ou GitHub CLI, ent√£o:
git remote add origin git@github.com:SEU_USUARIO/SEU_REPO.git
git push -u origin main


Verifique .env n√£o foi commitado.







9) Publicar no HuggingFace Spaces (Docker + Streamlit)

No HuggingFace: New ‚Üí Space ‚Üí escolha Docker + streamlit template.

Ao criar, v√° em Files ‚Üí substitua requirements.txt e src/streamlit_app.py com seus arquivos.

Em Settings ‚Üí Secrets adicione:

OPENAI_API_KEY ‚Üí value = sua nova chave

Clique em App para for√ßar rebuild.

Teste a interface p√∫blica.

Observa√ß√£o: se usar containers Docker custom, inclua vari√°veis de ambiente no Dockerfile se necess√°rio. O template Streamlit + Secret no HuggingFace √© geralmente suficiente.








10) Relat√≥rio / README / Slides (o que escrever para nota m√°xima)

Inclua no README.md (e no relat√≥rio entregue):

T√≠tulo e Integrantes

Objetivo (o que foi implementado)

Descri√ß√£o da arquitetura (OpenAI API, Streamlit, dataset IMDB)

Como rodar local (comandos exatos)

Como publicar no HuggingFace (passos resumidos)

Prompt final usado (cole o prompt JSON que voc√™ testou)

Resultados/avalia√ß√£o (m√©tricas, matriz de confus√£o, exemplos de classifica√ß√µes corretas / incorretas)

Limita√ß√µes e riscos (vi√©s, custo, erros do modelo)

Checklist de seguran√ßa (revoga√ß√£o de chave antiga, uso de secrets)

Anexos (prints do Streamlit, link do Space, link do GitHub)

Slides (sugest√£o 8‚Äì12 slides):

Slide 1: T√≠tulo & integrandes

2: Objetivo

3: Arquitetura (diagrama simples)

4: Dataset (IMDB)

5: Prompt + escolhas de design

6: Demonstra√ß√£o (prints ou URL)

7: M√©tricas e resultados

8: Trabalhos futuros / Conclus√£o

9: Refer√™ncias / cr√©ditos






11) Checklist final para nota m√°xima

Antes de entregar, confirme cada item abaixo:

 Nova chave OpenAI criada e antiga revogada.

 .env no .gitignore (sem chaves no repo).

 C√≥digo comentado e funcionando localmente (streamlit run).

 Reposit√≥rio no GitHub com README claro.

 Space p√∫blico no HuggingFace com Secret configurado.

 Prompt em vers√£o JSON e vers√£o com justificativa.

 Avalia√ß√£o com amostra do IMDB (m√©tricas incluidas no relat√≥rio).

 Slides prontos para apresenta√ß√£o.

 Link do Space e do GitHub anexados √† entrega.

 Demonstra√ß√µes: 5 exemplos com respostas corretas + 3 exemplos de erro analisados.

Erros comuns e como resolver

Response n√£o √© JSON ‚Üí tratar com try/except e extrair texto.

Rate limit / Timeouts ‚Üí implementar retries exponenciais.

API key exposta ‚Üí revogar imediatamente.

Aplica√ß√£o no HuggingFace n√£o builda ‚Üí ver logs, garantir requirements corretos e secret presente.

Custo alto ‚Üí reduzir max_tokens, diminuir n√∫mero de chamadas, usar amostras.

Se quiser, j√° fa√ßo agora (na mesma resposta) qualquer um destes itens prontos para copiar/colar:

streamlit_app.py final (com tratamento de erros + UI mais bonita).

classificador_sentimento.py final.

README.md completo pronto.

requirements.txt definitivo.

Modelo de slides (texto dos slides).

Me diga qual(is) desses quer que eu gere j√° (por exemplo: ‚Äúgera streamlit e README‚Äù).
